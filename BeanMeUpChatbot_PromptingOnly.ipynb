{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsW-jt3-b4HP",
        "outputId": "4c449156-1da3-46ac-b568-8320e1dcfced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsX4NC1GeUei",
        "outputId": "faf12a7c-9c14-4a7c-d205-67ee0345ea91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2cbR8Pi7XHT",
        "outputId": "c04d8fdb-5e5c-4dc0-a16c-597861b91315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import getpass\n",
        "\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load .env file\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "han8EI5wSBU4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_response(system_message, user_message):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message},\n",
        "            ],\n",
        "            temperature=0.7, #I tried varying this value from 0.7-1.1, 0.7 gave the best results\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except openai.error.AuthenticationError:\n",
        "            return \"Authentication Error: Check your API key.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "def offer_chain(reason, current_blend=None):\n",
        "\n",
        "    system_message = \"You are a fun, helpful, space-themed chatbot that creates personalized retention offers.\"\n",
        "    user_message = f\"\"\"\n",
        "          The user is considering canceling their subscription. Their reason is: {reason}.\n",
        "          {\"The user's current blend is: \" + current_blend + \".\" if current_blend else \"\"}\n",
        "          The available retention offers are 50% discount, pause for 6 months, skip next order.\n",
        "          Based on this information:\n",
        "          - Empathize with the user's reason.\n",
        "          - If applicable only for reasons such as feeling too jittery, not much energy boost, or not liking the taste, recommend a new blend from the four blends - Decaf: 10 mg caffeine, hints of hazelnut\n",
        "            ; Half-Caf: 50 mg caffeine, hints of vanilla ;  Regular Caf: 100 mg caffeine ; Super Caf: 200 mg caffeine.\n",
        "            if the user is already on the best blend, then say that you couldn't find a more suitable blend in the galaxy and just suggest the retention offer\n",
        "          - for other reasons, just offer one suitable retention offer\n",
        "          - Keep the tone light, fun, space-themed, and concise.\n",
        "          \"\"\"\n",
        "    return gpt_response(system_message, user_message)\n",
        "\n",
        "def handle_objection(objection_text, reason, offer_response):\n",
        "    \"\"\"Handle user objections using GPT.\"\"\"\n",
        "    system_message = \"You are a helpful, space-themed chatbot skilled at handling objections.\"\n",
        "    user_message = f\"\"\"\n",
        "The user has objected to the retention offer: {offer_response}.\n",
        "Their objection is: \"{objection_text}\".\n",
        "The user's reason for cancellation is: {reason}.\n",
        "Please:\n",
        "- Suggest an alternative offer from the available options-(50% discount, pause for 6 months, or skip next order).\n",
        "- Keep the tone light, fun, concise and space-themed.\n",
        "\"\"\"\n",
        "    return gpt_response(system_message, user_message)\n",
        "\n",
        "def prompt_chain():\n",
        "    # Reason Identification\n",
        "    reasons_prompt = \"\"\"\n",
        "          🚀 Greetings, Captain! Thanks for being a customer of Bean Me Up coffee. We are sorry that you are considering canceling your subscription. What is not working out for you?\n",
        "          Here are a few common reasons:\n",
        "          1️⃣ Too expensive\n",
        "          2️⃣ Too much coffee stocked up\n",
        "          3️⃣ Feeling too jittery\n",
        "          4️⃣ Not enough jittery or energy boost\n",
        "          5️⃣ Not a fan of the taste\n",
        "          6️⃣ Moving to a new house\n",
        "          \"\"\"\n",
        "    print(reasons_prompt)\n",
        "    reason_input = input(\"Your reason (1-6): \").strip()\n",
        "\n",
        "    reason_mapping = {\n",
        "        \"1\": \"too expensive\",\n",
        "        \"2\": \"too much coffee stocked up\",\n",
        "        \"3\": \"feeling too jittery\",\n",
        "        \"4\": \"not enough energy boost\",\n",
        "        \"5\": \"not a fan of the taste\",\n",
        "        \"6\": \"moving to a new house\",\n",
        "    }\n",
        "\n",
        "    if reason_input not in reason_mapping:\n",
        "        print(\"\\n🤔 Hmm, that’s not a valid choice. Let’s try again!\")\n",
        "        return prompt_chain()\n",
        "\n",
        "    reason = reason_mapping[reason_input]\n",
        "\n",
        "    #Blend Identification (if applicable)\n",
        "    current_blend = None\n",
        "    if reason_input in [\"3\", \"4\", \"5\"]:\n",
        "        print(\"\"\"\n",
        "Please select the Bean Me Up blend you are currently using:\n",
        "1️⃣ Decaf: 10 mg caffeine, hints of hazelnut\n",
        "2️⃣ Half-Caf: 50 mg caffeine, hints of vanilla\n",
        "3️⃣ Regular Caf: 100 mg caffeine\n",
        "4️⃣ Super Caf: 200 mg caffeine\n",
        "\"\"\")\n",
        "        blend_input = input(\"Your blend (1-4): \").strip()\n",
        "        blend_mapping = {\n",
        "            \"1\": \"Decaf: 10 mg caffeine, hints of hazelnut\",\n",
        "            \"2\": \"Half-Caf: 50 mg caffeine, hints of vanilla\",\n",
        "            \"3\": \"Regular Caf: 100 mg caffeine\",\n",
        "            \"4\": \"Super Caf: 200 mg caffeine\",\n",
        "        }\n",
        "        current_blend = blend_mapping.get(blend_input, None)\n",
        "\n",
        "        if not current_blend:\n",
        "            print(\"\\n🤔 Hmm, that’s not a valid choice. Let’s try again!\")\n",
        "            return prompt_chain()\n",
        "\n",
        "    #Generate Retention Offer\n",
        "    offer_response = offer_chain(reason, current_blend)\n",
        "    print(f\"\\n{offer_response}\")\n",
        "\n",
        "    #Handle Objections\n",
        "    objection = input(\"\\nWhat do you think? (yes/no) Please share your thoughts: \").strip()\n",
        "    if \"no\" in objection.lower():\n",
        "        objection_response = handle_objection(objection, reason, offer_response)\n",
        "        print(f\"\\n{objection_response}\")\n",
        "        objection = input(\"\\nWhat do you think? (yes/no)\").strip()\n",
        "        if(objection==\"yes\"):\n",
        "          print(\"\\nFantastic! Your new course is set. Live long and caffeinate! ☕️\")\n",
        "        else:\n",
        "          print(f\"\"\"\\nUnderstood, Captain. Your subscription has been successfully canceled.\n",
        "              If you ever wish to rejoin our galaxy of great coffee, we’ll be here. Warp speed ahead!\"\"\")\n",
        "\n",
        "    elif \"yes\" or \"okay\" or \"ok\" in objection.lower():\n",
        "        print(\"\\nFantastic! Your new course is set. Live long and caffeinate! ☕️\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"\\nLet me understand your thoughts better.\")\n",
        "        # checking the sentiment of the user input response to detect if the user is getting angry (could also do emotional analysis to get to more granularity)\n",
        "        sentiment_prompt = f\"Analyze the sentiment of the following text: '{objection}'. Reply with positive, negative, or neutral.\"\n",
        "        sentiment = gpt_response(\"You are a sentiment analysis assistant.\", sentiment_prompt).lower()\n",
        "\n",
        "        if sentiment == \"negative\":\n",
        "            print(f\"\"\"\\nWe’re sorry to hear you’re feeling this way, Captain. we’d love to make things right.\n",
        "                    How about trying a new blend, skipping your next delivery, or pausing your subscription for a while?\"\"\")\n",
        "            objection_response = handle_objection(objection, reason, offer_response)\n",
        "            print(f\"\\n{objection_response}\")\n",
        "        else:\n",
        "            print(\"\\nThanks for sharing! Let’s explore more options together.\")\n",
        "            prompt_chain()\n",
        "\n",
        "\n",
        "prompt_chain()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xDEBAi58MGYB",
        "outputId": "37d18f37-353d-4a6e-9d7c-04d7fc8b7718"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "          🚀 Greetings, Captain! Why are you considering canceling your subscription?\n",
            "          Here are a few common reasons:\n",
            "          1️⃣ Too expensive\n",
            "          2️⃣ Too much coffee stocked up\n",
            "          3️⃣ Feeling too jittery\n",
            "          4️⃣ Not enough jittery or energy boost\n",
            "          5️⃣ Not a fan of the taste\n",
            "          6️⃣ Moving to a new house\n",
            "          \n",
            "Your reason (1-6): 5\n",
            "\n",
            "Please select the Bean Me Up blend you are currently using:\n",
            "1️⃣ Decaf: 10 mg caffeine, hints of hazelnut\n",
            "2️⃣ Half-Caf: 50 mg caffeine, hints of vanilla\n",
            "3️⃣ Regular Caf: 100 mg caffeine\n",
            "4️⃣ Super Caf: 200 mg caffeine\n",
            "\n",
            "Your blend (1-4): 2\n",
            "\n",
            "🚀 Hey there, cosmic coffee explorer! 🌌\n",
            "\n",
            "I hear you about the taste not being out of this world. Sometimes our taste buds need a different orbit! Since you're currently on the Half-Caf with vanilla vibes, how about we launch you to a new flavor planet with our **Decaf** blend? It's got a gentle 10 mg caffeine kick and hazelnut notes that might just be stellar for your taste journey! 🌟\n",
            "\n",
            "And to make your taste adventure even sweeter, how about a **50% discount** on your next order? Just a little starry bonus to keep your coffee universe exciting.\n",
            "\n",
            "Let me know if you're ready for a delicious change in your coffee cosmos! 🌠☕️\n",
            "\n",
            "What do you think? (yes/no) Please share your thoughts: okay\n",
            "\n",
            "Let me understand your thoughts better.\n",
            "\n",
            "Thanks for sharing! Let’s explore more options together.\n",
            "\n",
            "          🚀 Greetings, Captain! Why are you considering canceling your subscription?\n",
            "          Here are a few common reasons:\n",
            "          1️⃣ Too expensive\n",
            "          2️⃣ Too much coffee stocked up\n",
            "          3️⃣ Feeling too jittery\n",
            "          4️⃣ Not enough jittery or energy boost\n",
            "          5️⃣ Not a fan of the taste\n",
            "          6️⃣ Moving to a new house\n",
            "          \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-11310b311409>\u001b[0m in \u001b[0;36m<cell line: 135>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mprompt_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-11310b311409>\u001b[0m in \u001b[0;36mprompt_chain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nThanks for sharing! Let’s explore more options together.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mprompt_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-11310b311409>\u001b[0m in \u001b[0;36mprompt_chain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m           \"\"\"\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreasons_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mreason_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your reason (1-6): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     reason_mapping = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aejWBaDHOB14"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}